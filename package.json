{
  "name": "opencode-zen-chat-provider",
  "publisher": "wienans",
  "displayName": "OpenCode Zen Provider",
  "description": "Provides OpenCode Zen models to VS Code's Language Model API.",
  "version": "0.1.1",
  "repository": {
    "type": "git",
    "url": "https://github.com/wienans/vsc-opencode-zen-chat-provider.git"
  },
  "license": "MIT",
  "engines": {
    "vscode": "^1.104.0"
  },
  "categories": [
    "AI",
    "Chat"
  ],
  "keywords": [
    "ai",
    "claude",
    "gpt",
    "agent",
    "coding",
    "assistant",
    "chat provider",
    "opencode"
  ],
  "icon": "assets/icon.png",
  "main": "./out/extension.js",
  "activationEvents": [
    "onStartupFinished",
    "onCommand:opencodeZen.setApiKey",
    "onCommand:opencodeZen.clearApiKey",
    "onCommand:opencodeZen.refreshModels",
    "onCommand:opencodeZen.selfTest"
  ],
  "contributes": {
    "languageModelChatProviders": [
      {
        "vendor": "opencode",
        "displayName": "OpenCode Zen"
      }
    ],
    "commands": [
      {
        "command": "opencodeZen.setApiKey",
        "title": "OpenCode Zen: Set API Key"
      },
      {
        "command": "opencodeZen.clearApiKey",
        "title": "OpenCode Zen: Clear API Key"
      },
      {
        "command": "opencodeZen.refreshModels",
        "title": "OpenCode Zen: Refresh Model List"
      },
      {
        "command": "opencodeZen.selfTest",
        "title": "OpenCode Zen: Self Test"
      }
    ],
    "configuration": {
      "title": "OpenCode Zen",
      "properties": {
        "opencodeZen.modelCacheTtlMinutes": {
          "type": "number",
          "default": 15,
          "minimum": 0,
          "description": "How long to cache models.dev model metadata before refetching. 0 disables caching."
        },
        "opencodeZen.promptCaching.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable prompt caching hints for supported providers (Anthropic, OpenAI, OpenAI-compatible)."
        },
        "opencodeZen.promptCaching.retention": {
          "type": "string",
          "enum": ["in_memory", "24h"],
          "default": "in_memory",
          "description": "Retention policy for OpenAI prompt caching. '24h' requires a compatible OpenAI model."
        },
        "opencodeZen.promptCaching.cacheKeyScope": {
          "type": "string",
          "enum": ["workspace", "global", "none"],
          "default": "workspace",
          "description": "Scope for the prompt cache key used by OpenAI/OpenAI-compatible providers."
        },
        "opencodeZen.promptCaching.anthropicTtl": {
          "type": "string",
          "enum": ["5m", "1h", "none"],
          "default": "5m",
          "description": "Anthropic cache_control TTL for cached message blocks. 'none' omits TTL."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "lint": "eslint"
  },
  "dependencies": {
    "@ai-sdk/anthropic": "^3.0.15",
    "@ai-sdk/openai": "^3.0.12",
    "@ai-sdk/openai-compatible": "^2.0.13",
    "ai": "^6.0.39"
  },
  "devDependencies": {
    "@eslint/js": "^9.13.0",
    "@stylistic/eslint-plugin": "^2.9.0",
    "@types/node": "^22.0.0",
    "@types/vscode": "^1.104.0",
    "@vscode/dts": "^0.4.1",
    "eslint": "^9.13.0",
    "typescript": "^5.9.2",
    "typescript-eslint": "^8.39.0"
  }
}
